{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0457337e",
   "metadata": {},
   "source": [
    "### DQN Performance and Hedging Behaviour - EDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4007c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from dqn_per import DQN\n",
    "from envs import TradingEnv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1426a381",
   "metadata": {},
   "source": [
    "### Training reward and Loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e29b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_num = 25\n",
    "df = pd.read_csv(f'history\\dqn\\Training{train_num}\\dqn_training_history.csv')\n",
    "\n",
    "#Smoothing function for training data \n",
    "def smooth(series, window=1000):\n",
    "    return series.rolling(window=window, min_periods=1).mean()\n",
    "\n",
    "df[\"reward_smooth\"] = smooth(df[\"reward\"])\n",
    "df[\"loss_smooth\"] = smooth(df[\"loss\"])\n",
    "\n",
    "\n",
    "#Plotting training data \n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 8), sharex=True)\n",
    "\n",
    "ax[0].plot(df[\"episode\"], df[\"reward_smooth\"], color = \"green\")\n",
    "ax[0].set_title(\"Smoothed Reward per Episode\")\n",
    "ax[0].set_ylabel(\"Average Reward\")\n",
    "ax[0].set_xlabel(\"Episode\")\n",
    "\n",
    "ax[1].plot(df[\"episode\"], df[\"loss_smooth\"], color = \"red\")\n",
    "ax[1].set_title(\"Smoothed Loss per Episode\")\n",
    "ax[1].set_ylabel(\"Average Loss\")\n",
    "ax[1].set_xlabel(\"Episode\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Reward_Loss_Episodes.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd2927a",
   "metadata": {},
   "source": [
    "### Loading in Environment and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439c4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "oos =10000\n",
    "cost_multiplier = 0\n",
    "kappa = 1/10\n",
    "env = TradingEnv(continuous_action_flag=False, sabr_flag=False, \n",
    "                    dg_random_seed= 1, spread=0.0, num_contract=1, \n",
    "                    init_ttm=10, trade_freq=1/5, num_sim=oos,kappa= kappa,cost_multiplier=cost_multiplier,\n",
    "                        mu =0, vol =0.01* np.sqrt(250), S = 100, K = 100, r = 0, q = 0)\n",
    "dqn = DQN(env)\n",
    "\n",
    "    # Load the trained model\n",
    "dqn.load(path = f\"model/dqn/Training{train_num}/dqn_model_282000.h5\")\n",
    "\n",
    "episode_rewards, dqn_actions, q_values = dqn.test(total_episode=oos)\n",
    "dqn_actions =np.array(dqn_actions)\n",
    "dqn_actions = np.insert(dqn_actions, 0, 0, axis=1)\n",
    "action = np.diff(dqn_actions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346ee175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select an episode to visualize\n",
    "episode_idx = 73  # Change this to the desired episode index\n",
    "\n",
    "# Extract Q-values, DQN actions, and delta hedging actions for the selected episode\n",
    "q_values_episode = np.array(q_values[episode_idx])  # Shape: (time_steps, num_actions)\n",
    "actions_episode = dqn_actions[episode_idx, 1:]  # Shape: (time_steps,)\n",
    "delta_actions_episode = env.delta_path[episode_idx, 1:] * 100  # Scale delta actions\n",
    "\n",
    "# Create the heatmap\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(q_values_episode.T, cmap=\"RdYlGn\", annot=False, cbar_kws={'label': 'Q-value'})\n",
    "\n",
    "# Overlay the chosen DQN actions\n",
    "time_steps = np.arange(1,q_values_episode.shape[0]+1)\n",
    "plt.plot(time_steps, actions_episode, 'k.', label=\"DQN Action\", markersize=8)\n",
    "\n",
    "# Overlay the delta hedging actions\n",
    "plt.plot(time_steps, delta_actions_episode, 'r--', color=\"orange\", label=\"Delta Hedging Action\", linewidth=1.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Time Step\", fontsize=12, labelpad=10)\n",
    "plt.ylabel(\"Action Index\", fontsize=12, labelpad=10)\n",
    "plt.title(f\"Q-value Heatmap with DQN and Delta Hedging Actions (Episode {episode_idx})\", fontsize=14, pad=15)\n",
    "\n",
    "# Set axis limits\n",
    "plt.xlim(1, 50)  # X-axis from time step 1 to 50\n",
    "plt.ylim(0, 100)  # Y-axis from 0 to 100\n",
    "\n",
    "# Add legend and save the plot\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Qvalues_Actions_Episode{episode_idx}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0252260",
   "metadata": {},
   "source": [
    "### Transaction Costs KDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2a6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate transaction costs based on delta hedging\n",
    "def cost(delta_h, multiplier):\n",
    "    TickSize = 0.1\n",
    "    return multiplier * TickSize * (np.abs(delta_h) + 0.01 * delta_h**2)\n",
    "\n",
    "\n",
    "#Calculating the transaction costs for the DQN Policy \n",
    "transaction_costs_dqn = cost(action, multiplier=cost_multiplier)\n",
    "total_costs_dqn = np.sum(transaction_costs_dqn, axis =1)\n",
    "\n",
    "#Calculating the transaction costs for the delta policy\n",
    "delta_path = env.delta_path*100\n",
    "delta_path_append = np.insert(delta_path, 0, 0, axis=1)\n",
    "delta_path.shape\n",
    "\n",
    "delta_h = np.diff(delta_path_append, axis=1)\n",
    "delta_h= delta_h[:, :-1]\n",
    "transaction_costs_delta= cost(delta_h, multiplier=cost_multiplier)\n",
    "total_costs_delta = np.sum(transaction_costs_delta, axis =1)\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# Plot histogram for the distribution of total hedging costs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(total_costs_dqn,  shade = False, color=\"green\", label='DQN Hedging Costs', bw_adjust=3)\n",
    "sns.kdeplot(total_costs_delta, shade = False, color=\"orange\", label='Delta Hedging Costs', bw_adjust=3)\n",
    "plt.xlim(0, )\n",
    "plt.xlabel(\"Total Hedging Cost\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Total Hedging Costs\")\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Hedging_Costs_Distribution.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from scipy.stats import t, f\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "avg_gamma = np.average(env.gamma_path, axis=1)\n",
    "total_costs = np.sum(transaction_costs_dqn, axis=1)\n",
    "\n",
    "X = avg_gamma.reshape(-1, 1)\n",
    "y = total_costs\n",
    "\n",
    "# Fit the regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Residuals\n",
    "residuals = y - y_pred\n",
    "\n",
    "# Degrees of freedom\n",
    "n = len(y)  # Number of observations\n",
    "p = X.shape[1] + 1  # Number of predictors + intercept\n",
    "df_residual = n - p  # Residual degrees of freedom\n",
    "df_model = p - 1  # Model degrees of freedom\n",
    "\n",
    "# Standard error of residuals\n",
    "residual_std_error = np.sqrt(np.sum(residuals**2) / df_residual)\n",
    "\n",
    "# Coefficients and standard errors\n",
    "X_with_intercept = np.hstack([np.ones((X.shape[0], 1)), X])  # Add intercept\n",
    "coef_cov_matrix = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * residual_std_error**2\n",
    "std_errors = np.sqrt(np.diag(coef_cov_matrix))\n",
    "\n",
    "# t-values and p-values for coefficients\n",
    "t_values = model.coef_ / std_errors[1:]\n",
    "t_values = np.insert(t_values, 0, model.intercept_ / std_errors[0])  # Add intercept t-value\n",
    "p_values = [2 * (1 - t.cdf(np.abs(t_val), df_residual)) for t_val in t_values]\n",
    "\n",
    "# R-squared and adjusted R-squared\n",
    "r_squared = r2_score(y, y_pred)\n",
    "adj_r_squared = 1 - (1 - r_squared) * (n - 1) / df_residual\n",
    "\n",
    "# F-statistic and p-value\n",
    "ssr = np.sum((y_pred - np.mean(y))**2)  # Regression sum of squares\n",
    "sse = np.sum(residuals**2)  # Sum of squared errors\n",
    "msr = ssr / df_model  # Mean square regression\n",
    "mse = sse / df_residual  # Mean square error\n",
    "f_stat = msr / mse  # F-statistic\n",
    "f_p_value = 1 - f.cdf(f_stat, df_model, df_residual)\n",
    "\n",
    "# Summary\n",
    "summary = f\"\"\"\n",
    "Call:\n",
    "LinearRegression(formula = total_costs ~ avg_gamma)\n",
    "\n",
    "Residuals:\n",
    "    Min      1Q  Median      3Q     Max \n",
    "{np.min(residuals):.3f}  {np.percentile(residuals, 25):.3f}  {np.median(residuals):.3f}  {np.percentile(residuals, 75):.3f}  {np.max(residuals):.3f}\n",
    "\n",
    "Coefficients:\n",
    "            Estimate    Std. Error    t value    Pr(>|t|)    \n",
    "(Intercept) {model.intercept_:.5f}   {std_errors[0]:.5f}   {t_values[0]:.2f}   {p_values[0]:.2e}    \n",
    "avg_gamma   {model.coef_[0]:.5f}   {std_errors[1]:.5f}   {t_values[1]:.2f}   {p_values[1]:.2e}    \n",
    "\n",
    "Residual standard error: {residual_std_error:.3f} on {df_residual} degrees of freedom\n",
    "Multiple R-squared:  {r_squared:.4f}, Adjusted R-squared:  {adj_r_squared:.4f}\n",
    "F-statistic: {f_stat:.2f} on {df_model} and {df_residual} DF,  p-value: {f_p_value:.2e}\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "# Plot the regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X, y, color='green', alpha=0.4, label='Data Points')\n",
    "plt.plot(X, y_pred, color='purple', linewidth=2, label='Regression Line')\n",
    "plt.xlabel('Average Gamma')\n",
    "plt.ylabel('Total Hedging Cost')\n",
    "plt.yticks(ticks=np.arange(0, np.max(y), step=10), labels=np.arange(0, np.max(y), step=10))\n",
    "plt.title('Regression of Total Hedging Cost of DQN agent on Average Gamma')\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Hedging_Costs_Regression.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4307506",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Apply polynomial transformation\n",
    "poly = PolynomialFeatures(degree=2)  # Try degree=2 or higher\n",
    "X_poly = poly.fit_transform(avg_gamma.reshape(-1, 1))\n",
    "\n",
    "# Fit the polynomial regression model\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(X_poly, total_costs)\n",
    "\n",
    "# Predictions\n",
    "y_pred_poly = model_poly.predict(X_poly)\n",
    "\n",
    "# Evaluate the fit\n",
    "r_squared_poly = r2_score(total_costs, y_pred_poly)\n",
    "print(f\"R-squared (Polynomial): {r_squared_poly:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3587c",
   "metadata": {},
   "source": [
    "## Total Profit & Loss t-statistic and volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64743087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# option value V_t \n",
    "v_t = env.option_price_path*100\n",
    "v_t_diff = np.diff(v_t, axis=1)\n",
    "\n",
    "# hedged position value \n",
    "s_t = env.path\n",
    "s_t_diff = np.diff(s_t, axis=1)\n",
    "\n",
    "# total pnl_t BS \n",
    "a_t_delta = delta_path[:, :-1]\n",
    "h_t_delta = a_t_delta*s_t_diff\n",
    "pi_t_delta = v_t_diff - h_t_delta - transaction_costs_delta\n",
    "total_pnl_delta = np.sum(pi_t_delta[:, 1:], axis = 1)\n",
    "\n",
    "# total pnl_t DQN\n",
    "a_t_dqn = dqn_actions[:, :-1]\n",
    "h_t_dqn = a_t_dqn * s_t_diff\n",
    "pi_t_dqn = v_t_diff - h_t_dqn - transaction_costs_dqn\n",
    "total_pnl_dqn = np.sum(pi_t_dqn[:,1:], axis = 1)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# Plot histogram for the distribution of total hedging costs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(total_pnl_delta, color=\"orange\", label='Delta Hedging PnL')\n",
    "sns.kdeplot(total_pnl_dqn, color=\"green\", label ='DQN Hedging PnL')\n",
    "plt.legend()\n",
    "plt.xlabel(\"Total Hedging PnL\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of Total PnL\")\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Hedging_PnL_Distribution.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53beefc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate statistical measures for total_pnl_dqn\n",
    "mean_pnl = np.mean(total_pnl_dqn)\n",
    "std_pnl = np.std(total_pnl_dqn, ddof=1)\n",
    "var_level = 0.05  # 5% VaR\n",
    "var_95 = np.percentile(total_pnl_dqn, 100 * var_level)\n",
    "cvar_95 = total_pnl_dqn[total_pnl_dqn <= var_95].mean()\n",
    "sharpe_ratio = mean_pnl / std_pnl if std_pnl != 0 else np.nan\n",
    "\n",
    "# Save results to CSV\n",
    "stats = {\n",
    "    \"Mean PnL\": mean_pnl,\n",
    "    \"Std PnL\": std_pnl,\n",
    "    \"5% VaR\": var_95,\n",
    "    \"5% CVaR\": cvar_95,\n",
    "    \"Sharpe Ratio\": sharpe_ratio\n",
    "}\n",
    "stats_df = pd.DataFrame([stats])\n",
    "stats_df.to_csv(f'history/dqn/Training{train_num}/Training{train_num}_DQN_PnL_Stats.csv', index=False)\n",
    "\n",
    "print(stats_df.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c370127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics for delta hedging\n",
    "mean_pnl_delta = np.mean(total_pnl_delta)\n",
    "std_pnl_delta = np.std(total_pnl_delta, ddof=1)\n",
    "var_level = 0.05  # 5% VaR\n",
    "var_95_delta = np.percentile(total_pnl_delta, 100 * var_level)\n",
    "cvar_95_delta = total_pnl_delta[total_pnl_delta <= var_95_delta].mean()\n",
    "sharpe_ratio_delta = mean_pnl_delta / std_pnl_delta if std_pnl_delta != 0 else np.nan\n",
    "\n",
    "# Save results to CSV\n",
    "stats = {\n",
    "    \"Mean PnL\": mean_pnl_delta,\n",
    "    \"Std PnL\": std_pnl_delta,\n",
    "    \"5% VaR\": var_95_delta,\n",
    "    \"5% CVaR\": cvar_95_delta,\n",
    "    \"Sharpe Ratio\": sharpe_ratio_delta\n",
    "}\n",
    "stats_df_delta = pd.DataFrame([stats])\n",
    "stats_df_delta.to_csv(f'history/dqn/Training{train_num}/Training{train_num}_Delta_PnL_Stats.csv', index=False)\n",
    "\n",
    "print(stats_df_delta.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adaee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a heatmap of the correlation between DQN actions, delta, and gamma for all episodes\n",
    "\n",
    "# Arrays to store correlations for each episode\n",
    "corr_matrix = []\n",
    "\n",
    "for ep in range(dqn_actions.shape[0]):\n",
    "    dqn_act = abs(action[ep,:])\n",
    "    delta_act = abs(delta_h[ep,:])\n",
    "    gamma = env.gamma_path[ep, 1:]\n",
    "    # Compute pairwise correlations\n",
    "    corr_ep = np.corrcoef([dqn_act, delta_act, gamma])\n",
    "    corr_matrix.append(corr_ep)\n",
    "\n",
    "# Convert to numpy array and average across episodes\n",
    "corr_matrix = np.array(corr_matrix)  # shape: (episodes, 3, 3)\n",
    "mean_corr = np.mean(corr_matrix, axis=0)\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(mean_corr, annot=True, cmap=\"coolwarm\", xticklabels=[\"DQN\", \"Delta\", \"Gamma\"], yticklabels=[\"DQN\", \"Delta\", \"Gamma\"])\n",
    "plt.title(\"Mean Correlation Heatmap: DQN, Delta, Gamma (across episodes)\")\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_CorrHeatMap_DQN_Delta_Gamma.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5d40a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "better_delta_idx = np.where(total_pnl_delta > total_pnl_dqn)[0]\n",
    "better_dqn_idx = np.where(total_pnl_dqn >= total_pnl_delta)[0]\n",
    "print(f\"Number of episodes where Delta outperforms DQN: {len(better_delta_idx)}\")\n",
    "\n",
    "# Visualize\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(total_pnl_delta - total_pnl_dqn, bins=50, color='gray')\n",
    "plt.axvline(0, color='blue', linestyle='--', label='Delta = DQN')\n",
    "plt.xlabel(\"Delta PnL - DQN PnL\")\n",
    "plt.ylabel(\"Episode Count\")\n",
    "plt.title(\"Episodes: Delta Hedging Outperforms DQN\")\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Delta_vs_DQN_PnL.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7aa2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_idx = better_dqn_idx[200]  # Change this to the desired episode index\n",
    "\n",
    "# Extract Q-values and actions for the selected episode\n",
    "q_values_episode = np.array(q_values[episode_idx])  # Shape: (time_steps, num_actions)\n",
    "actions_episode = dqn_actions[episode_idx, 1:]  # Shape: (time_steps,)\n",
    "delta_actions_episode = env.delta_path[episode_idx, 1:] * 100\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(q_values_episode.T, cmap=\"RdYlGn\", annot=False, cbar_kws={'label': 'Q-value'})\n",
    "\n",
    "# Overlay the chosen actions\n",
    "time_steps = np.arange(q_values_episode.shape[0])\n",
    "plt.plot(time_steps, actions_episode, 'k.', label=\"DQN Action\", markersize=8)\n",
    "\n",
    "# Overlay the delta hedging actions\n",
    "plt.plot(time_steps, delta_actions_episode, 'r--', label=\"Delta Hedging Action\", linewidth=1.5)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Time Step\", fontsize=12, labelpad=10)\n",
    "plt.ylabel(\"Action Index\", fontsize=12, labelpad=10)\n",
    "plt.title(f\"Q-value Heatmap with DQN and Delta Hedging Actions (Episode {episode_idx})\", fontsize=14, pad=15)\n",
    "plt.legend(fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_QValue_Heatmap_Episode_{episode_idx}.png')\n",
    "plt.show()\n",
    "\n",
    "stock_price_episode = env.path[episode_idx]\n",
    "\n",
    "# Plot stock price movement\n",
    "plt.figure(figsize=(7, 5))\n",
    "plt.plot(stock_price_episode, label=\"Stock Price\", color=\"blue\")\n",
    "plt.xlabel(\"Time Step\", fontsize=12, labelpad=10)\n",
    "plt.ylabel(\"Stock Price\", fontsize=12, labelpad=10)\n",
    "plt.title(f\"Stock Price Movement (Episode {episode_idx})\", fontsize=14, pad=15)\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_StockPrice_Episode_{episode_idx}.png')\n",
    "plt.show()\n",
    "\n",
    "colors = {\n",
    "    \"dqn_error\": \"#2ca02c\",  # Green\n",
    "    \"delta_error\": \"#ff7f0e\",  # Orange\n",
    "    \"dqn_cost\": \"#1f77b4\",  # Blue\n",
    "    \"delta_cost\": \"#d62728\",  # Red\n",
    "}\n",
    "\n",
    "# Create the combined plot\n",
    "plt.figure(figsize=(7, 5))\n",
    "\n",
    "# Plot hedging error\n",
    "plt.plot(v_t_diff[episode_idx] - h_t_dqn[episode_idx], label=\"DQN Hedging Error\", color=colors[\"dqn_error\"], linestyle=\"--\")\n",
    "plt.plot(v_t_diff[episode_idx] - h_t_delta[episode_idx], label=\"Delta Hedging Error\", color=colors[\"delta_error\"], linestyle=\"--\")\n",
    "\n",
    "# Plot hedging cost\n",
    "plt.plot(-transaction_costs_dqn[episode_idx], label=\"DQN Hedging Cost\", color=colors[\"dqn_cost\"], linestyle=\"-\")\n",
    "plt.plot(-transaction_costs_delta[episode_idx], label=\"Delta Hedging Cost\", color=colors[\"delta_cost\"], linestyle=\"-\")\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel(\"Time Step\", fontsize=12, labelpad=10)\n",
    "plt.ylabel(\"Value\", fontsize=12, labelpad=10)\n",
    "plt.title(f\"Hedging Error and Cost (Episode {episode_idx})\", fontsize=14, pad=15)\n",
    "plt.legend(fontsize=10, loc='upper left')  # Adjust legend position\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Hedging_Error_Cost_Episode_{episode_idx}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dda8573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate terminal portfolio values (last time step PnL)\n",
    "terminal_pnl_dqn = pi_t_dqn[:, -1]\n",
    "terminal_pnl_delta = pi_t_delta[:, -1]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(terminal_pnl_dqn, label=\"DQN\", color=\"green\", bw_adjust=1.2)\n",
    "sns.kdeplot(terminal_pnl_delta, label=\"Delta Hedge\", color=\"orange\", bw_adjust=1.2)\n",
    "plt.xlabel(\"Terminal Portfolio Value\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Terminal Portfolio Value\")\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Terminal_PnL.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab42136",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 6))\n",
    "plt.hexbin(terminal_pnl_dqn, terminal_pnl_delta, gridsize=50, cmap='viridis', mincnt=1)\n",
    "plt.plot([min(terminal_pnl_dqn), max(terminal_pnl_dqn)],\n",
    "         [min(terminal_pnl_dqn), max(terminal_pnl_dqn)], 'r--', label='45-degree line')\n",
    "plt.xlabel(\"DQN Terminal Portfolio Value\")\n",
    "plt.ylabel(\"Delta Hedge Terminal Portfolio Value\")\n",
    "plt.title(\"Hexbin: DQN vs Delta Terminal Portfolio Value\")\n",
    "plt.colorbar(label='Count')\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Hexbin_DQN_Delta.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pnl_dqn = np.std(pi_t_dqn, axis=1)\n",
    "std_pnl_delta = np.std(pi_t_delta, axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(std_pnl_dqn, label=\"DQN\", color=\"green\", bw_adjust=1.2)\n",
    "sns.kdeplot(std_pnl_delta, label=\"Delta Hedge\", color=\"orange\", bw_adjust=1.2)\n",
    "plt.xlabel(\"Std Dev of PnL within Episode\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Distribution of Std Dev of PnL within Episode\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec343882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average std dev in each hexbin\n",
    "plt.figure(figsize=(7, 6))\n",
    "hb = plt.hexbin(terminal_pnl_dqn, terminal_pnl_delta, C=std_pnl_dqn, \n",
    "                gridsize=50, cmap='viridis', reduce_C_function=np.mean, mincnt=1)\n",
    "plt.xlabel(\"DQN Terminal Portfolio Value\")\n",
    "plt.ylabel(\"Delta Hedge Terminal Portfolio Value\")\n",
    "plt.title(\"Hexbin: Terminal Value, Colored by Avg Std Dev (DQN)\")\n",
    "cb = plt.colorbar(hb)\n",
    "cb.set_label('Avg Std Dev of DQN PnL')\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Hexbin_Std_dev.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e028d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "pnl_percentiles = np.percentile(pi_t_dqn, percentiles, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "x = np.arange(pnl_percentiles.shape[1])\n",
    "\n",
    "# Shade between 5th and 95th percentile (light blue)\n",
    "plt.fill_between(x, pnl_percentiles[0], pnl_percentiles[-1], color='#ADD8E6', alpha=0.5)\n",
    "\n",
    "# Shade between 25th and 75th percentile (light yellow)\n",
    "plt.fill_between(x, pnl_percentiles[1], pnl_percentiles[3], color='#FFFACD', alpha=0.7)\n",
    "\n",
    "# Median line (50th percentile, bold)\n",
    "plt.plot(x, pnl_percentiles[2], color='blue', linewidth=2, label='Median (50th percentile)')\n",
    "\n",
    "# Percentile lines\n",
    "plt.plot(x, pnl_percentiles[0], color='#1E90FF', linestyle='--', linewidth=1, label='5th percentile')\n",
    "plt.plot(x, pnl_percentiles[1], color='#FFD700', linestyle='--', linewidth=1, label='25th percentile')\n",
    "plt.plot(x, pnl_percentiles[3], color='#FFD700', linestyle='--', linewidth=1, label='75th percentile')\n",
    "plt.plot(x, pnl_percentiles[4], color='#1E90FF', linestyle='--', linewidth=1, label='95th percentile')\n",
    "\n",
    "plt.xlabel(\"Time Step\", fontsize=13)\n",
    "plt.ylabel(\"PnL\", fontsize=13)\n",
    "plt.title(\"DQN PnL Distribution Over Time\", fontsize=15)\n",
    "plt.legend(loc='upper right', fontsize=11, frameon=True)\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_PnL_Percentile_Shaded.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8261c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_diff = np.abs(pi_t_dqn) - np.abs(pi_t_delta)\n",
    "mean_abs_diff = np.mean(abs_diff, axis=0)\n",
    "percentiles_diff = np.percentile(abs_diff, [5, 25, 50, 75, 95], axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(mean_abs_diff, label=\"Mean Difference (|DQN| - |Delta|)\")\n",
    "for i, p in enumerate([5, 25, 50, 75, 95]):\n",
    "    plt.plot(percentiles_diff[i], label=f\"{p}th percentile\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Difference in Absolute PnL\")\n",
    "plt.title(\"Difference in Absolute PnL (DQN - Delta) Over Time\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d8c3dc",
   "metadata": {},
   "source": [
    "### Metrics to be Mesaured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec23c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_pi_t_delta= np.std(pi_t_delta, axis = 1)\n",
    "n = pi_t_delta.shape[1]\n",
    "\n",
    "t_statistic_delta = np.sqrt(n)*(np.mean(pi_t_delta, axis = 1))/std_pi_t_delta\n",
    "\n",
    "std_pi_t_dqn= np.std(pi_t_dqn, axis = 1)\n",
    "n = pi_t_dqn.shape[1]\n",
    "\n",
    "t_statistic_dqn= np.sqrt(n)*(np.mean(pi_t_dqn, axis = 1))/std_pi_t_dqn\n",
    "\n",
    "# Plot the distribution of pi_t\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(t_statistic_delta, color=\"orange\", label=\"Student t-stat of Total PnL Delta policy\", bw_adjust=3)\n",
    "sns.kdeplot(t_statistic_dqn, color=\"green\", label=\"Student t-stat of Total PnL DQN policy\", bw_adjust=3)\n",
    "plt.xlabel(\"Student t-statistic of Total PnL\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot Student t-statistic of Total PnL\")\n",
    "\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Student_t_statistic.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833a7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute per-step changes in PnL\n",
    "pnl_diff_delta = np.diff(pi_t_delta, axis=1)  # Shape (10000, T-1)\n",
    "\n",
    "# Compute realized volatility per simulation\n",
    "realized_volatility_delta = np.std(pi_t_delta, axis=1)\n",
    "\n",
    "# Compute per-step changes in PnL\n",
    "pnl_diff_dqn = np.diff(pi_t_dqn, axis=1)  # Shape (10000, T-1)\n",
    "\n",
    "# Compute realized volatility per simulation\n",
    "realized_volatility_dqn= np.std(pi_t_dqn, axis=1)\n",
    "\n",
    "# Plot density of realized volatility\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(realized_volatility_delta, color=\"orange\", label=\"Realized Volatility of Total PnL Delta\")\n",
    "sns.kdeplot(realized_volatility_dqn, color=\"green\", label=\"Realized Volatility of Total PnL DQN\")\n",
    "plt.xlabel(\"Realized Volatility of Total PnL\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Density Plot of Realized Volatility of Total PnL\")\n",
    "\n",
    "# Set x-axis ticks every 5 steps\n",
    "x_ticks = np.arange(0, np.max(realized_volatility_dqn)+5, 5)  # Adjust range as needed\n",
    "plt.xticks(x_ticks)\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Realized_Volatility.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a4ca2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "\n",
    "# Find indices where delta outperforms DQN\n",
    "better_delta_idx = np.where(total_pnl_delta > total_pnl_dqn)[0]\n",
    "\n",
    "# Extract realized volatility for those episodes\n",
    "vol_delta_wins_dqn = realized_volatility_dqn[better_delta_idx]\n",
    "vol_delta_wins_delta = realized_volatility_delta[better_delta_idx]\n",
    "\n",
    "# Plot the distribution of realized volatility for these episodes\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(vol_delta_wins_dqn, label=\"DQN Realized Volatility (Delta Wins)\", color=\"green\", shade = False)\n",
    "sns.kdeplot(vol_delta_wins_delta, label=\"Delta Realized Volatility (Delta Wins)\", color=\"orange\", shade = False)\n",
    "plt.xlabel(\"Realized Volatility\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Realized Volatility When Delta Outperforms DQN\")\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Realized_Volatility_Delta_Wins.png')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Optionally, print summary statistics\n",
    "print(\"Mean DQN volatility (Delta wins):\", np.mean(vol_delta_wins_dqn))\n",
    "print(\"Mean Delta volatility (Delta wins):\", np.mean(vol_delta_wins_delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e60373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For episodes where delta wins, compute the mean cumulative PnL difference over time\n",
    "cum_pnl_diff = np.cumsum(pi_t_delta[better_delta_idx] - pi_t_dqn[better_delta_idx], axis=1)\n",
    "mean_cum_pnl_diff = np.mean(cum_pnl_diff, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(mean_cum_pnl_diff, label=\"Mean Cumulative PnL Difference (Delta - DQN)\", color=\"blue\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Mean Cumulative PnL Difference\")\n",
    "plt.title(\"Cumulative PnL Difference Over Time (Delta Wins Episodes)\")\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Cumulative_PnL_Difference.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For episodes where delta wins, compute cumulative PnL difference over time\n",
    "cum_pnl_diff = np.cumsum( pi_t_dqn[better_delta_idx]-pi_t_delta[better_delta_idx] , axis=1)\n",
    "\n",
    "# Compute percentiles at each time step\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "cum_pnl_percentiles = np.percentile(cum_pnl_diff, percentiles, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Shade between 5th and 95th percentile (light blue)\n",
    "plt.fill_between(range(cum_pnl_percentiles.shape[1]), cum_pnl_percentiles[0], cum_pnl_percentiles[-1], color='#ADD8E6', alpha=0.5, label='5th-95th percentile')\n",
    "# Shade between 25th and 75th percentile (light yellow)\n",
    "plt.fill_between(range(cum_pnl_percentiles.shape[1]), cum_pnl_percentiles[1], cum_pnl_percentiles[3], color='#FFFACD', alpha=0.7, label='25th-75th percentile')\n",
    "# Median line (bright red)\n",
    "plt.plot(cum_pnl_percentiles[2], color='blue', linestyle='-', linewidth=2, label='Median (50th percentile)')\n",
    "# Percentile lines\n",
    "plt.plot(cum_pnl_percentiles[0], color='#1E90FF', linestyle='--')\n",
    "plt.plot(cum_pnl_percentiles[1], color='#FFD700', linestyle='--')\n",
    "plt.plot(cum_pnl_percentiles[3], color='#FFD700', linestyle='--')\n",
    "plt.plot(cum_pnl_percentiles[4], color='#1E90FF', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Cumulative PnL Difference (DQN - Delta PnL)\")\n",
    "plt.title(\"Percentiles of Cumulative PnL Difference Over Time (DQN Underperforms Delta)\")\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Cumulative_PnL_Difference_Percentiles.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80125719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For episodes where delta wins, compute cumulative PnL difference over time\n",
    "random_indices = np.random.choice(better_dqn_idx, size=len(better_delta_idx), replace=True)\n",
    "\n",
    "cum_pnl_diff = np.cumsum(pi_t_dqn[random_indices] -pi_t_delta[random_indices] , axis=1)\n",
    "\n",
    "# Compute percentiles at each time step\n",
    "percentiles = [5, 25, 50, 75, 95]\n",
    "cum_pnl_percentiles = np.percentile(cum_pnl_diff, percentiles, axis=0)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Shade between 5th and 95th percentile (light blue)\n",
    "plt.fill_between(range(cum_pnl_percentiles.shape[1]), cum_pnl_percentiles[0], cum_pnl_percentiles[-1], color='#ADD8E6', alpha=0.5, label='5th-95th percentile')\n",
    "# Shade between 25th and 75th percentile (light yellow)\n",
    "plt.fill_between(range(cum_pnl_percentiles.shape[1]), cum_pnl_percentiles[1], cum_pnl_percentiles[3], color='#FFFACD', alpha=0.7, label='25th-75th percentile')\n",
    "# Median line (bright red)\n",
    "plt.plot(cum_pnl_percentiles[2], color='blue', linestyle='-', linewidth=2, label='Median (50th percentile)')\n",
    "# Percentile lines\n",
    "plt.plot(cum_pnl_percentiles[0], color='#1E90FF', linestyle='--')\n",
    "plt.plot(cum_pnl_percentiles[1], color='#FFD700', linestyle='--')\n",
    "plt.plot(cum_pnl_percentiles[3], color='#FFD700', linestyle='--')\n",
    "plt.plot(cum_pnl_percentiles[4], color='#1E90FF', linestyle='--')\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Cumulative PnL Difference (DQN - Delta PnL)\")\n",
    "plt.title(\"Percentiles of Cumulative PnL Difference Over Time (DQN outperforms Delta)\")\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Cumulative_PnL_Difference_Percentiles_DQN_Wins.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f8f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract gamma profiles for episodes where delta wins\n",
    "gamma_delta_wins = env.gamma_path[better_delta_idx, :]  # shape: (num_delta_wins, T)\n",
    "gamma_delta_lose = env.gamma_path[random_indices, :]  # shape: (num_delta_wins, T)\n",
    "\n",
    "# Plot mean gamma profile for these episodes\n",
    "mean_gamma_delta_wins = np.mean(gamma_delta_wins, axis=0)\n",
    "mean_gamma_delta_lose = np.mean(gamma_delta_lose, axis=0)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(mean_gamma_delta_wins, label=\"Mean Gamma (Delta has higher total PnL)\", color=\"purple\")\n",
    "plt.plot(mean_gamma_delta_lose, label=\"Mean Gamma (DQN has higher total PnL)\", color=\"gray\", linestyle=\"--\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Gamma\")\n",
    "plt.title(\"Mean Gamma Profile When Delta Outperforms DQN\")\n",
    "plt.legend()\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Mean_Gamma_Delta_Wins.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract stock paths for episodes where DQN outperforms Delta\n",
    "better_dqn_idx = np.where(total_pnl_dqn > total_pnl_delta)[0]\n",
    "stock_paths_dqn_wins = env.path[better_dqn_idx]\n",
    "\n",
    "# Plot stock paths for a few sample episodes\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(1, len(better_dqn_idx))):  # Plot up to 5 sample paths\n",
    "    plt.plot(stock_paths_dqn_wins[i], label=f'Episode {better_dqn_idx[i]}')\n",
    "\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"Stock Price\")\n",
    "plt.title(\"Stock Paths for Episodes Where DQN Outperforms Delta\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e09cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select episodes where delta wins\n",
    "better_delta_idx = np.where(total_pnl_delta > total_pnl_dqn)[0]\n",
    "\n",
    "# Extract DQN rewards and actions for these episodes\n",
    "rewards_delta_wins = [episode_rewards[i] for i in better_delta_idx]\n",
    "actions_delta_wins = dqn_actions[better_delta_idx]\n",
    "\n",
    "# Plot reward trajectories for a few sample episodes\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(5, len(better_delta_idx))):\n",
    "    plt.plot(rewards_delta_wins[i], label=f'Episode {better_delta_idx[i]}')\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"DQN Reward\")\n",
    "plt.title(\"Reward Trajectories for DQN (Delta Wins Episodes)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20874279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select episodes where delta wins\n",
    "better_dqn_idx = np.where(total_pnl_delta < total_pnl_dqn)[0]\n",
    "\n",
    "# Extract DQN rewards and actions for these episodes\n",
    "rewards_dqn_wins = [episode_rewards[i] for i in better_dqn_idx]\n",
    "actions_dqn_wins = dqn_actions[better_dqn_idx]\n",
    "\n",
    "# Plot reward trajectories for a few sample episodes\n",
    "plt.figure(figsize=(12, 6))\n",
    "for i in range(min(5, len(better_dqn_idx))):\n",
    "    plt.plot(rewards_dqn_wins[i], label=f'Episode {better_dqn_idx[i]}')\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"DQN Reward\")\n",
    "plt.title(\"Reward Trajectories for DQN (DQN Wins Episodes)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743ac051",
   "metadata": {},
   "source": [
    "### Comparing delta hegding path with DQN Path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf380fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "bs_delta = env.delta_path*100\n",
    "delta_path = np.insert(bs_delta, 0, 0, axis=1)\n",
    "delta_h = np.diff(delta_path, axis=1)\n",
    "stock_path = env.path\n",
    "\n",
    "\n",
    "for eps in range(73, 79, 2):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "    # Subplot 1: Stock price\n",
    "    axes[0].plot(stock_path[eps], label=\"stock price\")\n",
    "    axes[0].set_title(f\"Stock Price (Episode {eps})\")\n",
    "    axes[0].set_xlabel(\"Time Step\")\n",
    "    axes[0].set_ylabel(\"Price\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].legend()\n",
    "\n",
    "    # Subplot 2: Delta hedge vs DQN action\n",
    "    axes[1].plot(delta_path[eps][1:], label=\"delta hedge\", color=\"orange\")\n",
    "    axes[1].plot(dqn_actions[eps], label=\"dqn action\",  color=\"green\")\n",
    "    axes[1].set_xlabel(\"Time Step\")\n",
    "    axes[1].set_ylabel(\"Stock position\")\n",
    "    axes[1].set_title(f\"Delta vs DQN Action (Episode {eps})\")\n",
    "    axes[1].set_xlim(1, len(dqn_actions[eps]))\n",
    "    axes[1].grid(True)\n",
    "    axes[1].legend()\n",
    "\n",
    "    #Subplot 3: Total pnl\n",
    "    axes[2].plot(pi_t_delta[eps], label=\"Total PnL Delta\", color=\"orange\")\n",
    "    axes[2].plot(pi_t_dqn[eps], label=\"Total PnL DQN\", color=\"green\")\n",
    "    axes[2].set_title(f\"Total PnL (Episode {eps})\")\n",
    "    axes[2].set_xlabel(\"Time Step\")\n",
    "    axes[2].set_ylabel(\"Total PnL\")\n",
    "    axes[2].set_xlim(1, len(dqn_actions[eps]))\n",
    "    axes[2].text(0.02,0.55,\n",
    "                  f\"Total PnL Delta: {total_pnl_delta[eps]:.2f}\\nTotal PnL DQN: {total_pnl_dqn[eps]:.2f}\", \n",
    "                  transform=axes[2].transAxes,\n",
    "                  fontsize=12, \n",
    "                  verticalalignment='top',\n",
    "                  bbox=dict(boxstyle='round', edgecolor='black', facecolor='white', alpha=0.7))\n",
    "    axes[2].grid(True)\n",
    "    axes[2].legend()\n",
    "\n",
    "    # #Subplot 4: Reward Tracking \n",
    "    # axes[3].plot(episode_rewards[eps], label=\"dqn reward\",  color=\"green\")\n",
    "    # axes[3].set_xlabel(\"Time Step\")\n",
    "    # axes[3].set_ylabel(\"Reward\")\n",
    "    # axes[3].set_title(f\"Episode Rewards {eps})\")\n",
    "    # axes[3].grid(True)\n",
    "    # axes[3].legend()\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Stock_and_Action_TotalPnl_{eps}.png')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8674a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 21\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(-delta_path[eps][1:-1], label=\"delta hedge\", color=\"orange\")\n",
    "plt.plot(-dqn_actions[eps][1:], label=\"dqn action\",  color=\"#6495ED\")\n",
    "plt.plot(v_t_diff[eps], label=\"Option PnL\", color=\"#F08080\")\n",
    "plt.plot(-h_t_dqn[eps], label=\"Stock PnL \", color=\"green\")\n",
    "plt.plot(pi_t_dqn[eps], label=\"Total PnL\", color=\"black\", linestyle=\"--\")\n",
    "plt.xlabel(\"Time Step\")\n",
    "plt.ylabel(\"PnL\")\n",
    "plt.title(\"Out of Sample Simulation DQN\") \n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_OOS_Simulation_{eps}.png')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8bb4ca",
   "metadata": {},
   "source": [
    "### Policy Plots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57012d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttm_array = [10, 5, 0.2]\n",
    "\n",
    "for ttm in ttm_array:\n",
    "\n",
    "    dqn_otm = []\n",
    "    dqn_atm = []\n",
    "    dqn_itm = []\n",
    "\n",
    "    price_otm = 80\n",
    "    price_atm = 100\n",
    "    price_itm =120\n",
    "    strike = 100\n",
    "\n",
    "    stock_positions = np.arange(20,101,1)\n",
    "\n",
    "    for stock_position in stock_positions: \n",
    "        state_otm = [price_otm, stock_position, ttm]\n",
    "        action_otm= dqn.get_action(state_otm)\n",
    "        dqn_otm.append(action_otm-stock_position)\n",
    "\n",
    "        state_itm = [price_itm, stock_position, ttm]\n",
    "        action_itm= dqn.get_action(state_itm)\n",
    "        dqn_itm.append(action_itm-stock_position)\n",
    "\n",
    "        state_atm = [price_atm, stock_position, ttm]\n",
    "        action_atm= dqn.get_action(state_atm)\n",
    "        dqn_atm.append(action_atm-stock_position)\n",
    "\n",
    "\n",
    "    delta_itm= []\n",
    "    delta_atm = [] \n",
    "    delta_otm = []\n",
    "\n",
    "    stock_pos= np.arange(-20, -101, -1)\n",
    "\n",
    "    for i, pos in enumerate(stock_pos):\n",
    "        delta_itm.append(-100-pos)\n",
    "        delta_atm.append(-50-pos)\n",
    "        delta_otm.append(-pos)\n",
    "\n",
    "    light_red = \"#F08080\"\n",
    "    light_blue = \"#6495ED\"\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.scatter(-stock_positions, -np.array(dqn_otm), label=\"OTM DQN\", color=light_red, marker='*' )\n",
    "    plt.scatter(-stock_positions, -np.array(dqn_atm), label=\"ATM DQN\", color=light_blue)\n",
    "    plt.scatter(-stock_positions, -np.array(dqn_itm), label=\"ITM DQN\", color=\"green\", marker = 'D')\n",
    "    plt.plot(-stock_positions, delta_itm, label=\"ITM Delta\", color=\"green\", linestyle = \"dashdot\")\n",
    "    plt.plot(-stock_positions,delta_atm, label=\"ATM Delta\", color=light_blue, linestyle = \"dashed\")\n",
    "    plt.plot(-stock_positions,delta_otm, label=\"OTM Delta\", color=light_red, linestyle = \"dotted\")\n",
    "    plt.xlim(-10, -105)\n",
    "    # plt.text(0, 80, \"Long\", fontsize=14, color=\"black\",)  # Positive side\n",
    "    # plt.text(-5, -80, \"Short\", fontsize=14, color=\"black\",) \n",
    "    plt.xlabel(\"stock positions\")\n",
    "    plt.ylabel(\"Actions\", fontsize = 14)\n",
    "    plt.title(\"Policy Plot\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'history/dqn/Training{train_num}/Training{train_num}_Policy_Plot_{ttm}.png')\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "256388fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,  51,  57, ...,   1,   0,   0],\n",
       "       [  0,  51,  44, ..., 100, 100, 100],\n",
       "       [  0,  51,  53, ...,  99, 100,  98],\n",
       "       ...,\n",
       "       [  0,  51,  53, ...,  33,  45,   0],\n",
       "       [  0,  51,  57, ...,  18,  45,  98],\n",
       "       [  0,  51,  53, ...,  12,   1,   1]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dqn_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3353904c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-6e1506bca42f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdelta_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdelta_path\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdqn_flat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "# Flatten everything to 1D arrays\n",
    "dqn_flat = dqn_actions.flatten()\n",
    "delta_flat = delta_path.flatten()\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.scatter(delta_flat, dqn_flat, alpha=0.25)\n",
    "\n",
    "# Add 45Â° reference line\n",
    "min_val = min(delta_flat.min(), dqn_flat.min())\n",
    "max_val = max(delta_flat.max(), dqn_flat.max())\n",
    "plt.plot([min_val, max_val], [min_val, max_val], 'r--', label=\"Perfect Match\")\n",
    "\n",
    "plt.xlabel(\"Delta Hedge\")\n",
    "plt.ylabel(\"DQN Hedge\")\n",
    "plt.title(\"Scatter: DQN Hedge vs Delta Hedge (Aggregated Across All Paths)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
